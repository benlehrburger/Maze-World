# Maze-World

I implemented two problems and an informed search algorithm, A*, to solve them. The first problem entitled 'MazeworldProblem' features an arbitrary number of robots randomly placed in a maze with walls. The robots cannot move to a space with a wall or a space with another robot. Each robot has a specified goal location that they must reach.

How to solve this problem most efficiently? First, I had to outline what the successors of any given robot's state in the maze would look like. There are 5 possible actions: the robot can move north, south, east, or west by one coordinate, or it can stay in the same place. Then, I implemented an A* search algorithm to navigate through all of the possible successor states and choose those the shortest path. The A* algorithm uses two values to inform its decision: the cost to reach a node and the cost to get from that node to the goal. Minimizing the latter requires invoking an optimistic heuristic that never overestimates the distance from the node to the goal. I used the Manhattan distance to do this â€“ the straight line distance from a node to the goal. So, when A* searches for the most efficient next move, it chooses the successor state with minimal cost and Manhattan distance.

This is all well and good when we are dealt a robot with sensors that knows where it is. But what if a robot doesn't have sensors and doesn't know where it is? We can no longer use the same method to get succesors nor the same Manhattan heuristic distance because both require knowing the robot's current location in the maze. This all prompts the question: what is the most efficient way to drop a blind robot in a maze and have it narrow its belief states down to a single position?

This is the problem I faced in the second problem entitled 'SensorlessProblem.' The start state of the problem is every open tile in the maze, because the robot could be in any of them. Then, to get successors from a given state, I moved each coordinate in the current state one coordinate north, south, east, and west, respectively. However, we can only choose one direction to move in at a time. This is where the heuristic comes in. My heuristic is optimistic in that it chooses the successor state with the least number of belief states without ever overestimating that number of belief states. Then, A* traverses the maze, moving one cardinal direction at a time, until there is only one belief state left and the robot knows for certain where it is.
